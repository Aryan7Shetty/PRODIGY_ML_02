# -*- coding: utf-8 -*-
"""Prodigy_ML_Task2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fNwUi3-446xb-BxWqhx3gnt6zjdG5BLf
"""

from google.colab import files

# Upload CSV file
uploaded = files.upload()

import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Load the customer data
customer_data = pd.read_csv('Mall_Customers.csv')
customer_data

# Selecting relevant columns for clustering
X = customer_data.iloc[:, 2:]  # selecting Age, Annual Income, Spending Score

# Perform feature scaling
scaler = StandardScaler()
scaled_data = scaler.fit_transform(X)

# Determine the optimal number of clusters using the Elbow Method
inertia = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42, n_init=10)  # set n_init explicitly
    kmeans.fit(scaled_data)
    inertia.append(kmeans.inertia_)

# Plot the Elbow Method graph to determine the optimal number of clusters
plt.plot(range(1, 11), inertia)
plt.title('Elbow Method')
plt.xlabel('Number of Clusters')
plt.ylabel('Inertia')
plt.show()

# Based on the Elbow Method, choose the optimal number of clusters
optimal_clusters = 5

# Apply K-means clustering with the optimal number of clusters
kmeans = KMeans(n_clusters=optimal_clusters, init='k-means++', random_state=42, n_init=10)  # set n_init explicitly
cluster_labels = kmeans.fit_predict(scaled_data)

# Add the cluster labels to the original customer data
customer_data['Cluster'] = cluster_labels

# Plot the clusters
plt.figure(figsize=(10, 6))
for cluster in range(optimal_clusters):
    cluster_data = customer_data[customer_data['Cluster'] == cluster]
    plt.scatter(cluster_data['Annual Income (k$)'], cluster_data['Spending Score (1-100)'],
                label=f'Cluster {cluster}', s=50)

plt.title('Clusters of Customers')
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.legend()
plt.grid(True)
plt.show()